{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Unsupervised ML Example: Cyclohexane****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves as an example of how to analyze a simulation trajectory using unsupervised techniques. Here, specifically, we'll be analyzing a simulation of cyclohexane conformations, simulated using quantum-espresso, with metadynamics from PLUMED. The dataset and provenance can be found at:\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this notebook, you will need to install:\n",
    "    \n",
    "- [ase](https://wiki.fysik.dtu.dk/ase/index.html)\n",
    "- [scikit-learn](https://scikit-learn.org/)\n",
    "- [scikit-cosmo](https://github.com/cosmo-epfl/scikit-cosmo)\n",
    "- [librascal](https://github.com/cosmo-epfl/librascal)\n",
    "- [openTSNE](https://opentsne.readthedocs.io/en/latest/)\n",
    "\n",
    "in addition to standard packages [numpy](https://numpy.org/), [tqdm](https://github.com/tqdm/tqdm), and [matplotlib](https://matplotlib.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from functools import partial\n",
    "\n",
    "import ase\n",
    "import numpy as np\n",
    "from ase.io import read, write\n",
    "from matplotlib import pyplot as plt\n",
    "from openTSNE import TSNE\n",
    "from rascal.representations import SphericalInvariants as SOAP\n",
    "from skcosmo.preprocessing import StandardFlexibleScaler\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from utils import set_mpl_fonts, set_cmap\n",
    "\n",
    "set_mpl_fonts()\n",
    "cmap = set_cmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the frames from each MD simulation\n",
    "traj = []\n",
    "names = ['chair', 'twist-boat', 'boat', 'half-chair', 'planar']\n",
    "ranges = np.zeros((len(names), 2), dtype=int)\n",
    "conf_idx = np.zeros(len(names), dtype=int)\n",
    "\n",
    "for i, n in enumerate(names):\n",
    "    frames = read(f'./cyclohexane_data/sep_MD/{n}.xyz', ':')\n",
    "\n",
    "    for frame in frames:\n",
    "        # wrap each frame in its box\n",
    "        frame.wrap(eps=1E-10)\n",
    "\n",
    "        # mask each frame so that descriptors are only centered on carbon (#6) atoms\n",
    "        mask = np.zeros(len(frame))\n",
    "        mask[np.where(frame.numbers == 6)[0]] = 1\n",
    "        frame.arrays['center_atoms_mask'] = mask\n",
    "\n",
    "    ranges[i] = (len(traj), len(traj) + len(frames))\n",
    "    conf_idx[i] = len(traj)\n",
    "    traj = [*traj, *frames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# energies of the simulation frames\n",
    "energy = np.array([a.info['energy_eV'] for a in traj])\n",
    "\n",
    "# energies of the known conformers\n",
    "c_energy = np.array([traj[c].info['energy_eV'] for c in conf_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extrema for the energies\n",
    "max_e = max(energy)\n",
    "min_e = min(energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can confirm what our analysis will tell us: the simulation starts in the planar conformation, transitions to the metastable half-chair configuration, then moves through the boat configuration until it ultimately reaches the chair conformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(3*4.8528, 3*1.2219))\n",
    "\n",
    "# horizontal lines for each conformation\n",
    "for n, c, r in zip(names, c_energy, ranges):\n",
    "    \n",
    "    ax.plot(range(0, r[1] - r[0]),\n",
    "            energy[r[0]:r[1]] - min_e,\n",
    "#             c='lightgrey',\n",
    "            label=n,\n",
    "#             linestyle='--',\n",
    "#             alpha=0.8,\n",
    "            zorder=-1)\n",
    "    \n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Simulation Timestep\")\n",
    "ax.set_ylabel(\"Energy\")\n",
    "\n",
    "ax.set_xlim([0, len(energy)//5])\n",
    "ax.set_ylim([-0.1, 1.25 * (max_e - min_e)])\n",
    "ax.set_yticklabels([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/Figure5/energy.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Plotting of Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding(\n",
    "    embedding,\n",
    "    conf_embedding,\n",
    "    idx=range(len(traj)),\n",
    "    xlabel=r'$PC_1$',\n",
    "    ylabel=r'$PC_2$',\n",
    "    coloring=True,\n",
    "    cbar=True,\n",
    "    savename=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Helper function to make regression plots in later sections\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    embedding: projection of the simulation data, size (N, n_components)\n",
    "    conf_embedding: projection of the conformers, size (5, n_components)\n",
    "    idx: subselection of the simulation frames, array of int\n",
    "    xlabel: label for the x-axis, string\n",
    "    ylabel: label for the y-axis, string\n",
    "    coloring: whether or not to color datapoints by energies, boolean\n",
    "    cbar: whether or not to include a colorbar, boolean\n",
    "    \n",
    "    \"\"\"\n",
    "    if not cbar:\n",
    "        fig, ax = plt.subplots(1, figsize=(4, 4))\n",
    "    else:\n",
    "        fig, (ax, cax) = plt.subplots(1,2, figsize=(10.5, 8), gridspec_kw=dict(width_ratios=(6,1)))\n",
    "\n",
    "    p = ax.scatter(*embedding[:, :2].T,\n",
    "                   zorder=-1,\n",
    "                   c=energy[idx]-min_e if coloring else 'grey',\n",
    "                   vmax=max_e-min_e,\n",
    "                   vmin=0,\n",
    "                   cmap=cmap,\n",
    "                   s=4)\n",
    "    ax.scatter(\n",
    "        *conf_embedding[:, :2].T,\n",
    "        c=c_energy-min_e if coloring else 'grey',\n",
    "        s=200,\n",
    "        ec='k',\n",
    "        lw=2,\n",
    "        vmax=max_e-min_e,\n",
    "        vmin=0,\n",
    "        cmap=cmap,\n",
    "    )\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "\n",
    "    if cbar and coloring:\n",
    "        plt.colorbar(p, cax=cax, label='Energy, eV')\n",
    "        fig.subplots_adjust(hspace=1)\n",
    "    if savename is not None:\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        plt.savefig(savename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SOAP descriptors \n",
    "We create soap descriptor with the help of `rascal` library as below. The main important parameters are \n",
    "\n",
    "- `interaction_cutoff=2.5`: we are considering 2.5A radius of sphere for describing each atom environments. For cyclohexane, this includes both the nearest and second nearest carbons from each carbon center\n",
    "- `max_radial=6`: expand over 6 radial GTO bases\n",
    "- `max_angular=9`: expand over the first 9 spherical harmonics\n",
    "- `gaussian_sigma_constant=0.3`: assume each atom has a gaussian of size sigma=0.3 imposed on its lattice site\n",
    "\n",
    "Because we are focused on structure-level analysis, we average the descriptors for each configuration across all environmental centers and normalize to remove the feature means (we do the normalization explicitly in order to normalize both set of vectors by the same factors).\n",
    "\n",
    "For more information on SOAP vectors and their implementation in librascal, we point the readers to [(Bart√≤k 2012)](https://journals.aps.org/prb/pdf/10.1103/PhysRevB.87.184115), [(Musil 2017)](https://aip.scitation.org/doi/full/10.1063/1.5090481), [(Musil 2021)](https://aip.scitation.org/doi/full/10.1063/5.0044689), and [(Goscinski 2021)](https://aip.scitation.org/doi/full/10.1063/5.0057229)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = {\n",
    "    \"interaction_cutoff\": 2.5,\n",
    "    \"max_radial\": 6,\n",
    "    \"max_angular\": 9,\n",
    "    \"gaussian_sigma_constant\": 0.3,\n",
    "    \"gaussian_sigma_type\": \"Constant\",\n",
    "    \"cutoff_smooth_width\": 0.8,\n",
    "    \"radial_basis\": \"GTO\",\n",
    "    \"global_species\": [1, 6],\n",
    "    \"expansion_by_species_method\": \"user defined\",\n",
    "    \"normalize\": False\n",
    "}\n",
    "\n",
    "soap = SOAP(**hypers)\n",
    "normalizer = StandardFlexibleScaler(column_wise=False)\n",
    "\n",
    "soaps = normalizer.fit_transform(soap.transform(traj).get_features(soap))\n",
    "split_soaps = np.split(soaps, len(traj))\n",
    "mean_soaps = np.mean(split_soaps, axis=1)\n",
    "\n",
    "conf_split_soaps = np.array([split_soaps[ci] for ci in conf_idx])\n",
    "conf_mean_soaps = np.mean(conf_split_soaps, axis=1)\n",
    "\n",
    "# saving soap vectors\n",
    "np.savez('./cyclohexane_data/soap_vectors.npz',\n",
    "         mean_soaps=mean_soaps,\n",
    "         soaps=soaps,\n",
    "         conf_split_soaps=conf_split_soaps,\n",
    "         conf_mean_soaps=conf_mean_soaps)\n",
    "\n",
    "print(soaps.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using these SOAP vectors, we can detect the phase transition even when we do not know the energetics, solely the configurations.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis at via Linear Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Principal Components Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(mean_soaps)\n",
    "\n",
    "t_pca = pca.transform(mean_soaps)\n",
    "t_pca_conf = pca.transform(mean_soaps[conf_idx])\n",
    "\n",
    "plot_embedding(t_pca, t_pca_conf, savename='figures/Figure5/pca.eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even when our PCA is not easily interpretable, we can use it towards data compression by looking at the variance contained in the components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.loglog(pca.explained_variance_ratio_)\n",
    "plt.gca().set_xlabel(r'$n_{PC}$')\n",
    "plt.gca().set_ylabel(\"Explained Variance Ratio\")\n",
    "\n",
    "n_pca = np.where(np.cumsum(pca.explained_variance_ratio_) > 0.999)[0][0]\n",
    "plt.axvline(n_pca, c='k', linestyle='--')\n",
    "print(\n",
    "    \"This shows that we can retain most of the variance (>99.9%) in just {} vectors. We'll use this as our descriptor in some algorithms below for complexity's sake.\"\n",
    "    .format(n_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_desc = t_pca[:, :n_pca]\n",
    "conf_pca_desc = t_pca_conf[:, :n_pca]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('cyclohexane_data/pca.npz', pca=pca_desc, pca_conf=conf_pca_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE\n",
    "\n",
    "PCA is not intended as a clustering algorithm -- it just sometimes work out to give nice clusters.\n",
    "Let's employ one of the most popular non-linear dimensionality reduction algorithm in ML field `T-distributed Stochastic Neighbor Embedding (t-SNE)` to obtain 2 dimensional representation of our descriptor space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see how increasing the perplexity (number of expected neighbors) changes the layout of the projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexities = np.logspace(0, 2, 6, dtype=int)\n",
    "fig, ax = plt.subplots(1,\n",
    "                       len(perplexities),\n",
    "                       figsize=(4 * len(perplexities), 4),\n",
    "                      )\n",
    "\n",
    "for i, perp in enumerate(tqdm(perplexities)):\n",
    "    tsne = TSNE(\n",
    "        n_components=2,  # number of components to project across\n",
    "        perplexity=\n",
    "        perp,  # amount of neighbors one point is posited to have... play around with this!\n",
    "        metric=\"euclidean\",  # distance metric\n",
    "        n_jobs=2,  # parallelization\n",
    "        random_state=42,\n",
    "        verbose=False,\n",
    "    )\n",
    "    t_tsne = tsne.fit(pca_desc)\n",
    "    ax[i].scatter(*t_tsne.T, c=energy, cmap=cmap, s=2)\n",
    "    ax[i].axis('off')\n",
    "    ax[i].set_title(\"Perplexity = {}\".format(perp))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(\n",
    "    n_components=2,  # number of components to project across\n",
    "    perplexity=50,  # amount of neighbors one point is posited to have... play around with this!\n",
    "    metric=\"euclidean\",  # distance metric\n",
    "    n_jobs=2,  # parallelization\n",
    "    random_state=42,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_tsne = tsne.fit(pca_desc)\n",
    "t_tsne_conf = t_tsne.transform(conf_pca_desc)\n",
    "plot_embedding(t_tsne,\n",
    "               t_tsne_conf,\n",
    "               xlabel=r'$t-SNE_1$',\n",
    "               ylabel=r'$t-SNE_2$',\n",
    "               cbar=False,\n",
    "               savename='figures/Figure5/tsne.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('cyclohexane_data/tsne.npz', tsne=t_tsne, tsne_conf=t_tsne_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UMAP _should_ obtain similar results to t-sne, but with a shorter compute time. However, you will note a greater stochasticity to the projection when using a smaller number of neighbors -- this is due to the disconnection of the locally constructed manifolds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nneigh = np.maximum(2, np.logspace(0, 1.7, 5, dtype=int))\n",
    "fig, ax = plt.subplots(1,\n",
    "                       len(nneigh),\n",
    "                       figsize=(4*len(nneigh), 4),\n",
    "                      )\n",
    "\n",
    "for i, n in enumerate(tqdm(nneigh)):\n",
    "    um = umap.UMAP(n_components=2, n_neighbors=n, init='random')\n",
    "    um.fit(pca_desc)\n",
    "    t_um = um.transform(pca_desc)\n",
    "    ax[i].scatter(*t_um.T, c=energy, cmap=cmap, s=2)\n",
    "    ax[i].axis('off')\n",
    "    ax[i].set_title(\"# Neighbors = {}\".format(n))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um = umap.UMAP(n_components=2, n_neighbors=50)\n",
    "um.fit(pca_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_um = um.transform(pca_desc)\n",
    "t_um_conf = um.transform(conf_pca_desc)\n",
    "plot_embedding(t_um,\n",
    "               t_um_conf,\n",
    "               xlabel='UMAP(1)',\n",
    "               ylabel='UMAP(2)',\n",
    "               cbar=False,\n",
    "               savename='figures/Figure5/umap.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('cyclohexane_data/umap.npz', umap=t_um, umap_conf=t_um_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCovR\n",
    "\n",
    "PCovR is a dimensionality reduction technique that balances supervised and unsupervised learning. \n",
    "Here, we can use the parameter `mixing` to weight between unsupervised (0) and supervised (1). For more information, see the set of [PCovR / KPCovR tutorials](https://github.com/cosmo-epfl/kernel-tutorials), [(de Jong, 1992)](https://www.sciencedirect.com/science/article/pii/016974399280100I), and [(Helfrecht, 2020)](https://iopscience.iop.org/article/10.1088/2632-2153/aba9ef)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skcosmo.decomposition import PCovR\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# In PCovR, we first need to prepare a regression model\n",
    "# This prevents our decomposition from overfitting on the targets\n",
    "y = StandardFlexibleScaler(column_wise=True).fit_transform(np.vstack(energy))\n",
    "Yp = RidgeCV(cv=2, alphas=np.logspace(-10, 2),\n",
    "             fit_intercept=False).fit(mean_soaps, y).predict(mean_soaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcovr = PCovR(n_components=2, mixing=0.5)\n",
    "t_pcovr = pcovr.fit(pca_desc, Yp).transform(pca_desc)\n",
    "conf_t_pcovr = pcovr.transform(conf_pca_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embedding(t_pcovr,\n",
    "               conf_t_pcovr,\n",
    "               cbar=False,\n",
    "               xlabel=r'$PCov_1$',\n",
    "               ylabel=r'$PCov_2$',\n",
    "               savename='figures/Figure5/pcovr.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('cyclohexane_data/pcovr.npz', pcovr=t_pcovr, pcovr_conf=conf_t_pcovr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3), sharex=True, sharey=True)\n",
    "for ax, mixing in zip(axes, [0.0, 0.1, 0.5, 0.9, 1.0]):\n",
    "    pcovr = PCovR(n_components=2, mixing=mixing)\n",
    "    T = pcovr.fit(mean_soaps, Yp).transform(mean_soaps)\n",
    "\n",
    "    ax.scatter(T[:, 0],\n",
    "               T[:, 1],\n",
    "               c=energy,\n",
    "               zorder=-1,\n",
    "               vmax=max_e,\n",
    "               vmin=min_e,\n",
    "               cmap=cmap,\n",
    "               s=4)\n",
    "\n",
    "    ax.set_title(f'mixing={round(mixing, 4)}')\n",
    "    ax.set_xlabel(r\"$PCov_1$\")\n",
    "    \n",
    "axes[0].set_ylabel(r\"$PCov_2$\")\n",
    "axes[0].set_xticklabels([])\n",
    "axes[0].set_yticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Linear Dimensionality Reduction\n",
    "### Kernel Principal Components Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've seen similar results from most linear methods -- a plot which shows the high-energy conformers at the ends of the projection and some middling of low-energy conformers in the center. While this demonstrates the span of structures in the simulation, our low-energy conformers are often compressed in the middle of the mapping, as they are far more similar than the high-energy oscillations. Here, we can expand the enumeration of the low-energy conformers by taking a non-linear distance of the structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "from skcosmo.preprocessing import KernelNormalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When building a kernel on **averaged** representations, we construct our kernel such that\n",
    "\n",
    "$$K(\\mathcal{X}_A, \\mathcal{X}_{B}) = \\frac{\\sum_{i \\in A} \\sum_{j \\in B} k\\left(\\mathcal{X}_i, \\mathcal{X}_j\\right)}{N_A N_B}$$\n",
    "\n",
    "where the kernel between structures $A$ and $B$ is the average of the kernels of each of their atomic environments. With non-linear kernels, this is not equal to the kernel of the averaged representations, i.e.\n",
    "\n",
    "$$K(\\mathcal{X}_A, \\mathcal{X}_B) \\neq k\\left(\\sum_{i\\in A}\\frac{\\mathcal{X}_i}{N_A}, \\sum_{j\\in B}\\frac{\\mathcal{X}_j}{N_B}\\right)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you want to speed up this section, which can take a while:** just un-comment the lines marked \"simplify\" and comment those marked \"full calculation\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(range(len(traj)), 10000, replace=False) # simplify\n",
    "atom_idx = np.concatenate([range(i*6, (i+1)*6) for i in idx]) # simplify\n",
    "\n",
    "# idx = np.arange(len(traj)) # full calculation\n",
    "# atom_idx = np.arange(len(soaps)) # full calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "gamma = 5.0\n",
    "m = 6\n",
    "\n",
    "kernel = partial(pairwise_kernels, metric='rbf', gamma=gamma, n_jobs=6)\n",
    "\n",
    "# because we know that atom-ordering is conserved in this trajectory,\n",
    "# we'll only consider comparisons between identical atom indices\n",
    "# this would correspond with a `best-match` kernel\n",
    "K_raw = np.zeros((len(idx), len(idx)))\n",
    "\n",
    "my_soaps = np.reshape([split_soaps[i] for i in idx],\n",
    "                      (len(idx) * m, -1))\n",
    "\n",
    "for i in tqdm(range(len(idx))):\n",
    "    Ki = kernel(my_soaps[i * m:(i + 1) * m], my_soaps[i * m:])\n",
    "    for j in range(i, len(idx)):\n",
    "        K_raw[i, j] = K_raw[j, i] = np.mean(\n",
    "            np.diag(Ki[:, (j - i) * m:(j - i + 1) * m]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also construct a kernel between our simulation data and conformers\n",
    "# in order to embed them in the same latent space\n",
    "conf_K_raw = np.zeros((5, len(idx)))\n",
    "\n",
    "for i, ci in tqdm(enumerate(conf_idx)):\n",
    "    ki = kernel(split_soaps[ci], my_soaps)\n",
    "    for j in range(len(idx)):\n",
    "        conf_K_raw[i, j] = np.mean(np.diag(ki[:, j * m:(j + 1) * m]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with centered kernels is crucial (more on this in [Helfrecht, 2020](https://iopscience.iop.org/article/10.1088/2632-2153/aba9ef))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn = KernelNormalizer(with_trace=False).fit(K_raw)\n",
    "K = kn.transform(K_raw)\n",
    "conf_K = kn.transform(conf_K_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kpca = KernelPCA(n_components=n_pca, kernel='precomputed')\n",
    "kpca.fit(K)\n",
    "\n",
    "t_kpca = kpca.transform(K)\n",
    "t_kpca_conf = kpca.transform(conf_K)\n",
    "\n",
    "plot_embedding(t_kpca,\n",
    "               t_kpca_conf,\n",
    "               idx=idx,\n",
    "               xlabel=r'$KPCA_1$',\n",
    "               ylabel=r'$KPCA_2$',\n",
    "               cbar=False,\n",
    "               savename='figures/Figure5/kpca.eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see an 'unfolding' of the trajectory, where the high energy states are put closer together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# properties = {\"KPCA\": t_kpca,\n",
    "#              }\n",
    "# widget = chemiscope.show([traj[i] for i in idx], properties)\n",
    "# widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel PCovR\n",
    "PCovR can also be extended for non-linear distance metrics, here we can use our kernel computed in 2.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skcosmo.decomposition import KernelPCovR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "y = StandardFlexibleScaler(column_wise=True).fit_transform(np.vstack(energy))\n",
    "Yp = KernelRidge(kernel='precomputed', alpha=1E-4).fit(K, y[idx]).predict(K)\n",
    "kpcovr = KernelPCovR(n_components=2, mixing=0.5)\n",
    "t_kpcovr = kpcovr.fit(K, Yp).transform(K)\n",
    "conf_t_kpcovr = kpcovr.transform(conf_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embedding(t_kpcovr, conf_t_kpcovr, idx=idx,\n",
    "               cbar=False,\n",
    "               xlabel=r'$KPCov_1$',\n",
    "               ylabel=r'$KPCov_2$',\n",
    "               savename='figures/Figure5/kpcovr.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3), sharex=True, sharey=True)\n",
    "for ax, mixing in zip(axes, [0.0, 0.1, 0.5, 0.9, 1.0]):\n",
    "    kpcovr = KernelPCovR(n_components=2, mixing=mixing)\n",
    "    T = kpcovr.fit(K, Yp).transform(K)\n",
    "\n",
    "    ax.scatter(T[:, 0],\n",
    "               T[:, 1],\n",
    "               c=energy[idx],\n",
    "               zorder=-1,\n",
    "               vmax=max_e,\n",
    "               vmin=min_e,\n",
    "               cmap=cmap,\n",
    "               s=4)\n",
    "\n",
    "    ax.set_title(f'mixing={round(mixing, 4)}')\n",
    "    ax.set_xlabel(\"KPCov_1\")\n",
    "    \n",
    "axes[0].set_ylabel(\"KPCov_2\")\n",
    "axes[0].set_xticklabels([])\n",
    "axes[0].set_yticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Exploration\n",
    "Now we can export a chemiscope to play around with all of this on [chemiscope.org](chemiscope.org)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chemiscope\n",
    "properties = {\"PCA\": t_pca[:, :5],\n",
    "              \"t-SNE\": t_tsne,\n",
    "              \"UMAP\": t_um,\n",
    "              \"PCovR\": t_pcovr,\n",
    "             }\n",
    "widget = chemiscope.show(traj, properties)\n",
    "widget.save('cyclohexanes.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chemiscope\n",
    "properties = {\"PCA\": t_pca[:, :5],\n",
    "              \"t-SNE\": t_tsne,\n",
    "              \"UMAP\": t_um,\n",
    "              \"PCovR\": t_pcovr,\n",
    "             }\n",
    "widget = chemiscope.show(traj, properties)\n",
    "widget.save('cyclohexanes.json')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "186.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
