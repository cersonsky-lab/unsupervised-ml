{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3420e033",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32630ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ase\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ase.visualize import view\n",
    "import plotly.express as px\n",
    "from plotly.offline import init_notebook_mode, plot\n",
    "init_notebook_mode(connected=True)\n",
    "from ase.io import read\n",
    "from soapml.descriptors.soap import SOAP\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "from openTSNE import TSNE\n",
    "\n",
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f432ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.core.surface import generate_all_slabs, get_symmetrically_distinct_miller_indices, get_symmetrically_equivalent_miller_indices\n",
    "from pymatgen.symmetry.analyzer import SpacegroupAnalyzer\n",
    "from pymatgen.core import Structure\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84afee7",
   "metadata": {},
   "source": [
    "### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcb7af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_surface_sites(slab, height=2.5, only_species=None):\n",
    "    surf_sites = af.find_surface_sites_by_height(\n",
    "        slab,\n",
    "        2.5,\n",
    "    )\n",
    "    if only_species:\n",
    "        surf_sites = [\n",
    "            s for s in surf_sites if s.species_string in only_species\n",
    "        ]\n",
    "    surf_index = [i for i in range(len(slab)) if slab.sites[i] in surf_sites]\n",
    "    return surf_index\n",
    "\n",
    "\n",
    "#     new_sp = slab.site_properties\n",
    "#     new_sp['surface_properties'] = surf_props\n",
    "#     print('surface atoms:{}'.format(surf_props.count('surface')))\n",
    "#     slab = slab.copy(site_properties=new_sp)\n",
    "def list2tuple(a):\n",
    "    if a:\n",
    "        b = (a[0], a[1], a[2])\n",
    "    else:\n",
    "        b = (1, 0, 0)\n",
    "    return b\n",
    "\n",
    "\n",
    "def rattle(slab):\n",
    "    aseslab = AseAtomsAdaptor.get_atoms(slab)\n",
    "    positions = aseslab.positions\n",
    "    positions = positions + 0.05 * (2 * np.random.rand(len(positions), 3) - 1)\n",
    "    aseslab.positions = positions\n",
    "    frac_coord = aseslab.get_scaled_positions()\n",
    "    new_slab = slab.copy()\n",
    "    for i in range(len(new_slab)):\n",
    "        new_slab[i] = slab[i].species_string, frac_coord[i]\n",
    "    return new_slab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8335f61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial as spatial, scipy.cluster.hierarchy as hc\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import matplotlib\n",
    "from matplotlib.colors import ListedColormap\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl_logger = logging.getLogger('matplotlib')\n",
    "mpl_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# dist = k2d(Kmat)\n",
    "\n",
    "\n",
    "class clustermap_plot():\n",
    "    \"\"\"Author: Sandip De \"\"\"\n",
    "    def __init__(self, dist, envdf, linkage_method='complete'):\n",
    "\n",
    "        self.tdf = pd.DataFrame(\n",
    "            dist,\n",
    "            columns=envdf['center'].values,\n",
    "            index=envdf['center'].values,\n",
    "        )\n",
    "        self.linkage = hc.linkage(  #https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html#scipy.cluster.hierarchy.linkage\n",
    "            spatial.distance.squareform(dist),\n",
    "            method=linkage_method\n",
    "        )  #https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.squareform.html#scipy.spatial.distance.squareform\n",
    "        self.envdf = envdf\n",
    "\n",
    "    def plot(\n",
    "        self,\n",
    "        heatmap_palette='plasma',\n",
    "        col_palette='Reds',\n",
    "        row_palette='Blues',\n",
    "        centers=None,\n",
    "        envfrac=None,\n",
    "    ):\n",
    "\n",
    "        envdf = self.envdf\n",
    "        tdf = self.tdf\n",
    "        linkage = self.linkage\n",
    "\n",
    "        if not centers: centers = list(envdf.center.unique())\n",
    "        if not envfrac: envfrac = centers\n",
    "\n",
    "        max_count = envdf[envfrac].values.max()\n",
    "        min_count = 0\n",
    "\n",
    "        cmap = ListedColormap(sns.color_palette(col_palette, 256))\n",
    "\n",
    "        norm = plt.Normalize(0, max_count)\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm.set_array([])\n",
    "\n",
    "        col_colors = pd.DataFrame({}, columns=envfrac)\n",
    "\n",
    "        for sp in envfrac:\n",
    "            labels = envdf[sp].values\n",
    "            labels = (labels / max_count)\n",
    "            col_colors[sp] = pd.DataFrame(labels)[0].map(cmap)\n",
    "        col_colors.index = tdf.index\n",
    "\n",
    "        center_map = {c: i for (c, i) in zip(centers, range(len(centers)))}\n",
    "\n",
    "        cmap = ListedColormap(sns.color_palette(row_palette, 256))\n",
    "\n",
    "        row_colors = pd.DataFrame({}, columns=centers)\n",
    "\n",
    "        for sp in centers:\n",
    "\n",
    "            labels = envdf['center'].apply(lambda x: 1.0\n",
    "                                           if x == sp else 0).values\n",
    "            #             labels = (labels - np.min(labels)) / (np.max(labels) - np.min(labels))\n",
    "            row_colors[sp] = pd.DataFrame(labels)[0].map(cmap)\n",
    "\n",
    "\n",
    "#         row_colors = pd.DataFrame(row_colors)\n",
    "        row_colors.index = tdf.index\n",
    "\n",
    "        g = sns.clustermap(\n",
    "            tdf,\n",
    "            row_linkage=linkage,\n",
    "            col_linkage=linkage,\n",
    "            row_cluster=True,\n",
    "            col_cluster=True,\n",
    "            col_colors=col_colors,\n",
    "            row_colors=row_colors,\n",
    "            yticklabels=100,\n",
    "            #                ylabel='test',\n",
    "            xticklabels=100,\n",
    "            figsize=(10, 10),\n",
    "            cbar_pos=(1.1, .2, .03, .4),\n",
    "            cmap=heatmap_palette)\n",
    "\n",
    "        # g.fig.suptitle('Figure Title \\n \\n ')\n",
    "        g.ax_heatmap.set_xlabel('Surface Atom Local Environments')\n",
    "        g.ax_heatmap.set_ylabel('Surface Atoms Local Environment')\n",
    "        g.ax_col_dendrogram.set_title(\n",
    "            'Clustering of {} Surface Atom Environments Based on SOAP Descriptors'\n",
    "            .format(len(tdf)),\n",
    "            fontsize=15)\n",
    "        #         g.ax_col_dendrogram.set_ylabel('fractions')\n",
    "        g.fig.text(\n",
    "            1.02,\n",
    "            0.76,\n",
    "            'Number of atoms\\nin the environment',\n",
    "            wrap=True,\n",
    "            horizontalalignment='left',\n",
    "            #             fontsize=15\n",
    "        )\n",
    "\n",
    "        g.fig.text(\n",
    "            0.1,\n",
    "            -0.01,\n",
    "            'Environment Centers',\n",
    "            wrap=True,\n",
    "            horizontalalignment='left',\n",
    "            #             fontsize=15\n",
    "        )\n",
    "\n",
    "        divider = make_axes_locatable(g.ax_cbar)\n",
    "\n",
    "        cax = divider.append_axes(\n",
    "            'right',\n",
    "            size='100%',\n",
    "            pad=0.5,\n",
    "        )\n",
    "        cax.set_ylabel('number of atoms')\n",
    "        g.fig.colorbar(sm, cax=cax, orientation='vertical')\n",
    "        return g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5509ac17",
   "metadata": {},
   "source": [
    "## Data Generation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f443e69",
   "metadata": {},
   "source": [
    "### Start from Bulk structure\n",
    "We read in a bulk crystal structure for MnIn2O4 from Materials project (mp-35162) as our starting structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37c4576",
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk = Structure.from_file('../surface_analysis_data/Mn2In4O8_mp-35162.cif')\n",
    "bulk=SpacegroupAnalyzer(bulk).get_conventional_standard_structure()\n",
    "view(AseAtomsAdaptor.get_atoms(bulk)*[1,1,1],viewer='ngl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5acfce2",
   "metadata": {},
   "source": [
    "### Generate some slabs\n",
    "We utilize pymatgen functions to generate symmetrically distinct possible slabs upto miller index of 2 and make sure to get a resoanble surfaece area by repeating the unitcells as required to get x and y cell lengths at least 8 A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea5f6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "slabs=generate_all_slabs(bulk,min_slab_size=10,min_vacuum_size=10,max_index=2,)\n",
    "for i in range(len(slabs)):\n",
    "    slab=slabs[i]\n",
    "    scale=[1,1,1]\n",
    "    if slab.lattice.a <8:\n",
    "        scale[0]=int(np.ceil(8.0/slab.lattice.a))\n",
    "    if slab.lattice.b<8:\n",
    "        scale[1]=int(np.ceil(8.0/slab.lattice.b))\n",
    "#     print(scale)\n",
    "    slabs[i].make_supercell(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3d5152",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"Generated {len(slabs)} slabs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b7e55",
   "metadata": {},
   "source": [
    "### Modify few surface atoms\n",
    "Next we identify Indium atoms on the surface and replace two of them by Aluminum atoms by all possible ways. We also rattle the atoms to break the symmetry just to highlight the power of this analysis approach which does not rely on symmetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e196767",
   "metadata": {},
   "outputs": [],
   "source": [
    "tslabs=[]\n",
    "for slab in slabs:\n",
    "    \n",
    "    surf_sites=get_surface_sites(slab,only_species=['In'])\n",
    "    \n",
    "    for (site1,site2) in combinations(surf_sites,2):\n",
    "        \n",
    "        new_slab=slab.copy()\n",
    "        new_slab[site1]='Al'\n",
    "        new_slab[site2]='Al'\n",
    "        \n",
    "        \n",
    "        new_slab=rattle(new_slab) #rattle the atoms to break symmetry\n",
    " \n",
    "        tslabs.append(new_slab)\n",
    "print (f\"Generated {len(tslabs)} slabs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6155e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "view(AseAtomsAdaptor.get_atoms(tslabs[10])*[1,1,1],viewer='ngl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f478cce7",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55d7fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "dump(tslabs,'../surface_analysis_data/surface_models.job')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e7c80d",
   "metadata": {},
   "source": [
    "## Analysis \n",
    "In this section we will not analyse the models that we have created in the previous section. you can just load the models if you have not gone through the previous section. The plan is to analyse local environments of the surface atoms only. The motivation for doing this could be because we want to understand different surface morphologies across different terminations. As an action item one could be interested in understanding possible Oxygen vacancy defects and want to look into main group of Oxygen atoms for which vacancy formation energy calculations should be prioritized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7036f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "tslabs=load('../surface_analysis_data/surface_models.job')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cee2abc",
   "metadata": {},
   "source": [
    "### Create descriptors \n",
    "We are going to use SOAP descriptors for our purpose here. The following code will identify the surface atoms upto depth of 4.5 A from top layer and create SOAP descriptors for all the atoms that satisfy this selection criteria. As additional information for us to understand how the descriptors capture certain simple aspects (eg number of certian atoms in the local environment) we also extract these informations which will be used to validate the observations.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7454da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from dscribe.descriptors import SOAP\n",
    "from tqdm import tnrange, tqdm_notebook, notebook\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "\n",
    "surface_site_list = []\n",
    "all_slabs_ase = []\n",
    "all_env_data = []\n",
    "rcut = 4.5\n",
    "center_sp_list=['O','In','Mn','Al']\n",
    "with notebook.tnrange(len(tslabs)) as pbar:\n",
    "\n",
    "    for slab in tslabs:\n",
    "        \n",
    "        \n",
    "        all_slabs_ase.append(AseAtomsAdaptor.get_atoms(slab))\n",
    "\n",
    "        surface_sites=get_surface_sites(slab,height=4.5,only_species=center_sp_list)\n",
    "        \n",
    "        surface_site_list.append(surface_sites)\n",
    "\n",
    "        for isite in surface_sites:\n",
    "\n",
    "            envdata = {}\n",
    "\n",
    "            envdata['center'] = slab[isite].specie.symbol\n",
    "\n",
    "            nn = slab.get_neighbors(slab[isite], rcut)\n",
    "\n",
    "            nn.append(slab[isite])\n",
    "\n",
    "            s = Structure.from_sites(nn)\n",
    "\n",
    "            envdata['structure'] = s.as_dict()\n",
    "\n",
    "            env = [a.specie.symbol for a in nn]\n",
    "\n",
    "            for sp in np.unique(env):\n",
    "                envdata[sp] = env.count(sp)\n",
    "\n",
    "            envdata['miller_index'] = list2tuple(slab.miller_index)\n",
    "            all_env_data.append(envdata)\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "envdf = pd.DataFrame(all_env_data)\n",
    "\n",
    "species = ['In', 'O','Mn','Al']\n",
    "rcut = rcut\n",
    "nmax = 9\n",
    "lmax = 9\n",
    "\n",
    "# Setting up the SOAP descriptor\n",
    "soap = SOAP(\n",
    "    species=species,\n",
    "    periodic=True,\n",
    "    rcut=rcut,\n",
    "    sigma=0.7,\n",
    "    sparse=False,\n",
    "    nmax=nmax,\n",
    "    lmax=lmax,dtype='float64'\n",
    "\n",
    ")\n",
    "\n",
    "soapdesc = soap.create(all_slabs_ase, positions=surface_site_list, n_jobs=10)\n",
    "tdesc = []\n",
    "for i in range(len(all_slabs_ase)):\n",
    "    d = soapdesc[i]\n",
    "    for j in range(len(d)):\n",
    "        tdesc.append(d[j])\n",
    "tdesc=np.array(tdesc)\n",
    "soapdesc = normalize(tdesc, axis=1) # normalize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acadc0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(soapdesc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca3b13e",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction\n",
    "We start by attempting to reduce dimensionality of the descriptor space "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a6e792",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d04ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=100)\n",
    "pca.fit(soapdesc)\n",
    "plt.plot(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d44137",
   "metadata": {},
   "source": [
    "We make a conservative choice of keeping the number of component upto `explained_variance_ratio > 0.001`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c136963",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comp=np.max(np.where(pca.explained_variance_ratio_>0.001)[0])\n",
    "n_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8eecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "soapdesc_pca=pca.transform(soapdesc)[:,0:n_comp+1]\n",
    "np.shape(soapdesc_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaa06c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "descdf=pd.DataFrame({'comp_{}'.format(i): soapdesc_pca[:,i] for i in range(len(soapdesc_pca[0]))})\n",
    "descdf['center']=envdf.center.values\n",
    "sns.pairplot(descdf[[*descdf.columns[0:4],'center']],hue='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae6699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "descdf=pd.DataFrame({'comp_{}'.format(i): soapdesc_pca[:,i] for i in range(len(soapdesc_pca[0]))})\n",
    "descdf['O_count']=envdf.O.values\n",
    "sns.pairplot(descdf[[*descdf.columns[0:4],'O_count']],hue='O_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b40b6f4",
   "metadata": {},
   "source": [
    "#### TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59844ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openTSNE import TSNE\n",
    "tsne = TSNE(\n",
    "    n_components=2,\n",
    "    perplexity=500,\n",
    "    metric=\"euclidean\",\n",
    "    n_jobs=40,\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7469c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding=tsne.fit(soapdesc_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b89e76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.scatterplot(embedding[:,0],embedding[:,1],hue=envdf.O.values,palette='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cd560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.scatterplot(embedding[:,0],embedding[:,1],hue=envdf.center.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4f503a",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "\n",
    "Before jumping in to clustering algorithms, let's first create the distance matrix and visualize it. We are using euclidean distance here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db70013",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dist = squareform(pdist(soapdesc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aa643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e58a39",
   "metadata": {},
   "source": [
    "#### Hierarchical Clustering \n",
    "\n",
    "We are using a convenient utility class defined before for this purpose here. Feel free to change the linkage_method to any of the following: `ward`,`single`,`average`,`median`,`centroid` to explore the impact of the choices. In the book we have explained what these choices mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73870f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sns.reset_orig()\n",
    "dist = squareform(pdist(soapdesc_pca))\n",
    "clmap = clustermap_plot(dist, envdf=envdf.fillna(0), linkage_method='ward')\n",
    "clmap.plot(envfrac=['Mn', 'In', 'O', 'Al'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48990073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.cluster as cluster\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_context('poster')\n",
    "sns.set_color_codes()\n",
    "plot_kwds = {'alpha' : 0.25, 's' : 80, 'linewidths':0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be7a0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(embedding[:,0], embedding[:,1], c='b', **plot_kwds)\n",
    "frame = plt.gca()\n",
    "frame.axes.get_xaxis().set_visible(False)\n",
    "frame.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b88718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672c67d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(descriptors, algorithm, args, kwds,map_data=[],ref_labels=[]):\n",
    "    start_time = time.time()\n",
    "    plt.figure(figsize=(10,10))\n",
    "    labels = algorithm(*args, **kwds).fit_predict(descriptors)\n",
    "    nclusters=len(np.unique(labels))\n",
    "    end_time = time.time()\n",
    "    palette = sns.color_palette('deep', np.unique(labels).max() + 1)\n",
    "    colors = [palette[x] if x >= 0 else (0.0, 0.0, 0.0) for x in labels]\n",
    "    \n",
    "    if len(map_data)==0: map_data=descriptors[:,0:2]\n",
    "        \n",
    "    plt.scatter(map_data[:,0], map_data[:,1], c=colors, **plot_kwds)\n",
    "    frame = plt.gca()\n",
    "    frame.axes.get_xaxis().set_visible(False)\n",
    "    frame.axes.get_yaxis().set_visible(False)\n",
    "    plt.title('{} Clusters found by {}'.format(nclusters,str(algorithm.__name__)), fontsize=24)\n",
    "    plt.text(-0.5, 0.7, 'Clustering took {:.2f} s'.format(end_time - start_time), fontsize=14)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfd4fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(soapdesc_pca, cluster.KMeans, (), {'n_clusters':6},map_data=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8102b70d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ca5349",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=plot_clusters(soapdesc_pca, cluster.KMeans, (), {'n_clusters':6},map_data=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf36e291",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_labels= envdf.center.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebab9755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_mutual_info_score,adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f91d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score(ref_labels,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c6c3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(soapdesc_pca, cluster.MeanShift, (), {'cluster_all':True},map_data=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211b411d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(soapdesc_pca, cluster.AgglomerativeClustering, (), {'n_clusters':4},map_data=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4dedbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(pdist(soapdesc_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf735cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(soapdesc_pca, cluster.DBSCAN, (), {'eps':0.38},map_data=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c588362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "plot_clusters(soapdesc_pca, hdbscan.HDBSCAN, (), {'min_cluster_size':200},map_data=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcb9876",
   "metadata": {},
   "outputs": [],
   "source": [
    "kneedloc=KneeLocator(np.arange(len(pca.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f0ae09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Edelweiss0.1",
   "language": "python",
   "name": "edelweiss0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
